Implementation of "[Attention is all you need](https://arxiv.org/abs/1706.03762)" paper in PyTorch.

Original code credits: [here](https://github.com/hkproj/pytorch-transformer)